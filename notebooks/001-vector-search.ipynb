{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment and run the following cells if you work on Google Colab :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/kstathou/vector_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd vector_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from vector_engine.utils import vector_search, id2details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stored and processed data in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read files from S3 buckets!\n",
    "df = pd.read_csv('s3://vector-search-blog/misinformation_papers.csv')\n",
    "df = df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>citations</th>\n",
       "      <th>id</th>\n",
       "      <th>is_EN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>Migrant women and sexual and gender-based viol...</td>\n",
       "      <td>Abstract Background Sexual and Gender-Based Vi...</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>3092205359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         original_title  \\\n",
       "7191  Migrant women and sexual and gender-based viol...   \n",
       "\n",
       "                                               abstract  year  citations  \\\n",
       "7191  Abstract Background Sexual and Gender-Based Vi...  2020          0   \n",
       "\n",
       "              id  is_EN  \n",
       "7191  3092205359      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misinformation, disinformation and fake news papers: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Misinformation, disinformation and fake news papers: {df.id.unique().shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Sentence Transformers library](https://github.com/UKPLab/sentence-transformers) offers pretrained transformers that produce SOTA sentence embeddings. Checkout this [spreadsheet](https://docs.google.com/spreadsheets/d/14QplCdTCDwEmTqrn1LH4yrbKvdogK4oQvYO1K1aPR5M/) with all the available models.\n",
    "\n",
    "In this tutorial, we will use the `distilbert-base-nli-stsb-mean-tokens` model which has the best performance on Semantic Textual Similarity tasks among the DistilBERT versions. Moreover, although it's slightly worse than BERT, it is quite faster thanks to having a smaller size.\n",
    "\n",
    "I use the same model in [Orion's semantic search engine](https://www.orion-search.org/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245M/245M [00:40<00:00, 5.98MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Instantiate the sentence-level DistilBERT\n",
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(torch.device(\"cuda\"))\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc530688be8d4cb28b26e74121132ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=4.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert abstracts to vectors\n",
    "embeddings = model.encode(df.abstract.to_list(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the vectorised abstract: (768,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the vectorised abstract: {embeddings[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector similarity search with Faiss\n",
    "[Faiss](https://github.com/facebookresearch/faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, even ones that do not fit in RAM. \n",
    "\n",
    "Faiss is built around the `Index` object which contains, and sometimes preprocesses, the searchable vectors. Faiss has a large collection of [indexes](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes). You can even create [composite indexes](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes-(composite)). Faiss handles collections of vectors of a fixed dimensionality d, typically a few 10s to 100s.\n",
    "\n",
    "**Note**: Faiss uses only 32-bit floating point matrices. This means that you will have to change the data type of the input before building the index before building.\n",
    "\n",
    "To learn more about Faiss, you can read their paper on [arXiv](https://arxiv.org/abs/1702.08734).\n",
    "\n",
    "Here, we will the `IndexFlatL2` index:\n",
    "- It's a simple index that performs a brute-force L2 distance search\n",
    "- It scales linearly. It will work fine with our data but you might want to try [faster indexes](https://github.com/facebookresearch/faiss/wiki/Faster-search) if you work will millions of vectors.\n",
    "\n",
    "To create an index with the `misinformation` abstract vectors, we will:\n",
    "1. Change the data type of the abstract vectors to float32.\n",
    "2. Build an index and pass it the dimension of the vectors it will operate on.\n",
    "3. Pass the index to IndexIDMap, an object that enables us to provide a custom list of IDs for the indexed vectors.\n",
    "4. Add the abstract vectors and their ID mapping to the index. In our case, we will map vectors to their paper IDs from MAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the Faiss index: 100\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Change data type\n",
    "embeddings = np.array([embedding for embedding in embeddings]).astype(\"float32\")\n",
    "\n",
    "# Step 2: Instantiate the index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "# Step 3: Pass the index to IndexIDMap\n",
    "index = faiss.IndexIDMap(index)\n",
    "\n",
    "# Step 4: Add vectors and their IDs\n",
    "index.add_with_ids(embeddings, df.id.values)\n",
    "\n",
    "print(f\"Number of vectors in the Faiss index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching the index\n",
    "The index we built will perform a k-nearest-neighbour search. We have to provide the number of neighbours to be returned. \n",
    "\n",
    "Let's query the index with an abstract from our dataset and retrieve the 10 most relevant documents. **The first one must be our query!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>citations</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9300</th>\n",
       "      <td>Neural data-to-text generation: A comparison b...</td>\n",
       "      <td>Traditionally, most data-to-text applications ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>2969686025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>QANet: Combining Local Convolution with Global...</td>\n",
       "      <td>Current end-to-end machine reading and questio...</td>\n",
       "      <td>2018</td>\n",
       "      <td>221</td>\n",
       "      <td>2798858969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>Maximizing Stylistic Control and Semantic Accu...</td>\n",
       "      <td>Neural generation methods for task-oriented di...</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>2964239055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12845</th>\n",
       "      <td>ConvBERT: Improving BERT with Span-based Dynam...</td>\n",
       "      <td>Pre-trained language models like BERT and its ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>3047171714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Distributed Representations of Sentences and D...</td>\n",
       "      <td>Many machine learning algorithms require the i...</td>\n",
       "      <td>2014</td>\n",
       "      <td>1985</td>\n",
       "      <td>2949547296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>ANN-based Innovative Segmentation Method for H...</td>\n",
       "      <td>Artificial Neural Network (ANN) s has widely b...</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>2161423555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>Vietnamese Open Information Extraction</td>\n",
       "      <td>Open information extraction (OIE) is the proce...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>2775071667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>Convolutional neural network compression for n...</td>\n",
       "      <td>Convolutional neural networks are modern model...</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>2803928583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>Recognizing Extended Spatiotemporal Expression...</td>\n",
       "      <td>Precise geocoding and time normalization for t...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>1946516469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10170</th>\n",
       "      <td>Answering Conversational Questions on Structur...</td>\n",
       "      <td>We present a novel approach to answering seque...</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>2970281864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          original_title  \\\n",
       "9300   Neural data-to-text generation: A comparison b...   \n",
       "4534   QANet: Combining Local Convolution with Global...   \n",
       "9427   Maximizing Stylistic Control and Semantic Accu...   \n",
       "12845  ConvBERT: Improving BERT with Span-based Dynam...   \n",
       "841    Distributed Representations of Sentences and D...   \n",
       "...                                                  ...   \n",
       "283    ANN-based Innovative Segmentation Method for H...   \n",
       "6305              Vietnamese Open Information Extraction   \n",
       "5630   Convolutional neural network compression for n...   \n",
       "1630   Recognizing Extended Spatiotemporal Expression...   \n",
       "10170  Answering Conversational Questions on Structur...   \n",
       "\n",
       "                                                abstract  year  citations  \\\n",
       "9300   Traditionally, most data-to-text applications ...  2019          0   \n",
       "4534   Current end-to-end machine reading and questio...  2018        221   \n",
       "9427   Neural generation methods for task-oriented di...  2019          0   \n",
       "12845  Pre-trained language models like BERT and its ...  2020          0   \n",
       "841    Many machine learning algorithms require the i...  2014       1985   \n",
       "...                                                  ...   ...        ...   \n",
       "283    Artificial Neural Network (ANN) s has widely b...  2009         13   \n",
       "6305   Open information extraction (OIE) is the proce...  2018          0   \n",
       "5630   Convolutional neural networks are modern model...  2018          8   \n",
       "1630   Precise geocoding and time normalization for t...  2015          0   \n",
       "10170  We present a novel approach to answering seque...  2019          0   \n",
       "\n",
       "               id  \n",
       "9300   2969686025  \n",
       "4534   2798858969  \n",
       "9427   2964239055  \n",
       "12845  3047171714  \n",
       "841    2949547296  \n",
       "...           ...  \n",
       "283    2161423555  \n",
       "6305   2775071667  \n",
       "5630   2803928583  \n",
       "1630   1946516469  \n",
       "10170  2970281864  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural data-to-text generation: A comparison between pipeline and end-to-end architectures'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paper title\n",
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Traditionally, most data-to-text applications have been designed using a modular pipeline architecture, in which non-linguistic input data is converted into natural language through several intermediate transformations. In contrast, recent neural models for data-to-text generation have been proposed as end-to-end approaches, where the non-linguistic input is rendered in natural language with much less explicit intermediate representations in-between. This study introduces a systematic comparison between neural pipeline and end-to-end data-to-text approaches for the generation of text from RDF triples. Both architectures were implemented making use of state-of-the art deep learning methods as the encoder-decoder Gated-Recurrent Units (GRU) and Transformer. Automatic and human evaluations together with a qualitative analysis suggest that having explicit intermediate steps in the generation process results in better texts than the ones generated by end-to-end approaches. Moreover, the pipeline models generalize better to unseen inputs. Data and code are publicly available.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paper abstract\n",
    "df.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance: [0.0, 88.87393188476562, 91.87527465820312, 93.9849853515625, 95.50212860107422, 95.56340026855469, 95.60047912597656, 96.01769256591797, 96.63569641113281, 97.08345794677734]\n",
      "\n",
      "MAG paper IDs: [2969686025, 2803928583, 2625324377, 3089046173, 2964910501, 2810809989, 3012813596, 3009445007, 2898799786, 3089952842]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the 10 nearest neighbours\n",
    "D, I = index.search(np.array([embeddings[0]]), k=10)\n",
    "print(f'L2 distance: {D.flatten().tolist()}\\n\\nMAG paper IDs: {I.flatten().tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the paper titles based on their index\n",
    "id2details(df, I, 'original_title')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
